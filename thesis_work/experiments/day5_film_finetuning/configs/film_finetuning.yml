# FiLM-Only Fine-Tuning Configuration
# Loads pretrained checkpoint, freezes EGNN, trains only FiLM adapter

run_name: "film-finetuning-Bigger-film"
logdir: "thesis_work/experiments/day5_film_finetuning/outputs"
wandb_params:
  mode: "online"
  entity: null
  group: "film-finetuning"

# Dataset
dataset: "crossdock" # Must match pretrained checkpoint (not crossdock_full)
datadir: "data/processed_crossdock_noH_full_fixed" # Data with correct 10-feature pocket encoding
esmc_path: "data/processed_crossdock_noH_full_fixed" # Directory with {split}_esmc.npz

# Pretrained checkpoint (EGNN will be frozen)
film_only_training: true # NEW: freeze EGNN, train only FiLM

# Training - optimized for FiLM-only
batch_size: 16
lr: 1.0e-3 # Higher LR ok for small adapter
n_epochs: 50 # Much fewer epochs needed
num_workers: 4
gpus: 1
clip_grad: true

# Model architecture (must match pretrained checkpoint)
mode: "pocket_conditioning"
pocket_representation: "full-atom"
virtual_nodes: false

egnn_params:
  device: "cuda"
  edge_cutoff_ligand: null
  edge_cutoff_pocket: 5.0
  edge_cutoff_interaction: 5.0
  reflection_equivariant: false
  joint_nf: 128
  hidden_nf: 256
  n_layers: 6
  attention: true
  tanh: true
  norm_constant: 1
  inv_sublayers: 1
  sin_embedding: false
  aggregation_method: "sum"
  normalization_factor: 100

diffusion_params:
  diffusion_steps: 500
  diffusion_noise_schedule: "polynomial_2"
  diffusion_noise_precision: 5.0e-4
  diffusion_loss_type: "l2"
  normalize_factors: [1, 4]

# Evaluation
eval_epochs: 10
visualize_sample_epoch: 0 # Set to 0 to disable, or N to visualize every N epochs
visualize_chain_epoch: 0 # Set to 0 to disable, or N to visualize every N epochs
eval_params:
  n_eval_samples: 5 # Reduced for faster evaluation
  eval_batch_size: 3
  smiles_file: "data/processed_crossdock_noH_full_fixed/train_smiles.npy"
  n_visualize_samples: 3
  keep_frames: 100

# Other
log_every_n_steps: 1 # Log train loss every step
enable_progress_bar: true
num_sanity_val_steps: 0
augment_rotation: false
augment_noise: 0
auxiliary_loss: false
loss_params:
  max_weight: 0.001
  schedule: "linear"
  clamp_lj: 3.0
