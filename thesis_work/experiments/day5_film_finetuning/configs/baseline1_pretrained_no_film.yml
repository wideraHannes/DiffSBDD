# Baseline 1: Pretrained Checkpoint Only (No FiLM)
# Purpose: Establish ground truth for what "good" performance looks like
# Expected: Connectivity >95%, Validity >95%, QED 0.4-0.6, Loss 0.5-0.6

run_name: "baseline1-pretrained-no-film-v1"
logdir: "thesis_work/experiments/day5_film_finetuning/outputs/baselines"
wandb_params:
  mode: "online"
  entity: null
  group: "film-baselines"

# Dataset
dataset: "crossdock" # Must match pretrained checkpoint
datadir: "data/dummy_dataset"
esmc_path: null # No ESM-C embeddings needed for this baseline

# Baseline 1 configuration: NO FiLM
film_only_training: false # Not training, just evaluating
use_film: false # DISABLE FiLM completely
film_mode: "identity" # Ignored when use_film=false

# Training disabled (evaluation only)
batch_size: 2
lr: 1.0e-3
n_epochs: 1 # Just run 1 epoch for evaluation
num_workers: 4
gpus: 1
clip_grad: true

# Model architecture (must match pretrained checkpoint)
mode: "pocket_conditioning"
pocket_representation: "full-atom"
virtual_nodes: false

egnn_params:
  device: "cuda"
  edge_cutoff_ligand: null
  edge_cutoff_pocket: 5.0
  edge_cutoff_interaction: 5.0
  reflection_equivariant: false
  joint_nf: 32
  hidden_nf: 128
  n_layers: 5
  attention: true
  tanh: true
  norm_constant: 1
  inv_sublayers: 1
  sin_embedding: false
  aggregation_method: "sum"
  normalization_factor: 100

diffusion_params:
  diffusion_steps: 500
  diffusion_noise_schedule: "polynomial_2"
  diffusion_noise_precision: 5.0e-4
  diffusion_loss_type: "l2"
  normalize_factors: [1, 4]

# Evaluation
eval_epochs: 1 # Evaluate immediately
visualize_sample_epoch: 0
visualize_chain_epoch: 0
eval_params:
  n_eval_samples: 5 # More samples for baseline
  eval_batch_size: 1
  smiles_file: "data/dummy_dataset/train_smiles.npy"
  n_visualize_samples: 3
  keep_frames: 100

# Other
log_every_n_steps: 1
enable_progress_bar: true
num_sanity_val_steps: 0
augment_rotation: false
augment_noise: 0
auxiliary_loss: false
loss_params:
  max_weight: 0.001
  schedule: "linear"
  clamp_lj: 3.0
